{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19c96c72-438d-406b-a1a3-f6f969ada565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading modules, paths, and models\n",
    "\n",
    "import numpy as np, pandas as pd, pathlib, joblib\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error, mean_squared_error, r2_score, accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "BASE = pathlib.Path.cwd().parents[0]\n",
    "DATA_PROCESSED = BASE / \"data\" / \"processed\"\n",
    "MODELS = BASE / \"models\"\n",
    "REPORTS = BASE / \"reports\"\n",
    "MODELS.mkdir(exist_ok=True)\n",
    "REPORTS.mkdir(exist_ok=True)\n",
    "\n",
    "SYMBOLS = [\"QQQ\", \"VFV.TO\", \"XEQT.TO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3353d927-b41e-4f72-8a66-fc139c3d8a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def load_dataset(symbol: str) -> pd.DataFrame:\n",
    "    df = pd.read_parquet(DATA_PROCESSED / f\"{symbol}_dataset.parquet\")\n",
    "    return df.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "def make_X_y(df: pd.DataFrame, task: str):\n",
    "    feats = df.drop(columns=[\"date\",\"y_reg\",\"y_cls\"])\n",
    "    X = feats.values.astype(float)\n",
    "    if task == \"reg\":\n",
    "        y = df[\"y_reg\"].values\n",
    "    else:\n",
    "        y = df[\"y_cls\"].values\n",
    "    return X, y, feats.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85a97485-dc0c-47d5-89f5-604ff4c84750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation and scorers for performance metrics\n",
    "def tscv(n_splits=5):\n",
    "    return TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "# Regression scorers (primary = negative RMSE)\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "rmse_scorer = make_scorer(rmse, greater_is_better=False)\n",
    "mae_scorer  = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "r2_scorer   = make_scorer(r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45465444-810f-4ca2-b3be-1ad3ced48a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establishing grids for the different models.\n",
    "ridge_grid = {\n",
    "    \"ridge__alpha\": [0.01, 0.1, 1.0, 5.0, 10.0, 50.0, 100.0]\n",
    "}\n",
    "\n",
    "hgb_grid = {\n",
    "    \"hgb__learning_rate\": [0.03, 0.05, 0.08, 0.1],\n",
    "    \"hgb__max_depth\": [3, 5, None],\n",
    "    \"hgb__max_leaf_nodes\": [15, 31, 63],\n",
    "    \"hgb__min_samples_leaf\": [10, 20, 50]\n",
    "}\n",
    "\n",
    "logit_grid = {\n",
    "    \"logit__C\": [0.1, 0.5, 1.0, 2.0, 5.0],\n",
    "    \"logit__penalty\": [\"l2\"],   # keep simple/portable\n",
    "    \"logit__solver\": [\"lbfgs\"], # supports l2 + probas\n",
    "    \"logit__max_iter\": [200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7138e0fe-935e-4f6b-9d3f-203be1235a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to tune the models using GridSearch Cross Validation\n",
    "def tune_ridge(symbol: str, n_splits=5):\n",
    "    df = load_dataset(symbol)\n",
    "    X, y, feat_names = make_X_y(df, \"reg\")\n",
    "\n",
    "    pipe = Pipeline([(\"scaler\", StandardScaler()), (\"ridge\", Ridge())])\n",
    "    gs = GridSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_grid=ridge_grid,\n",
    "        scoring={\"rmse\": rmse_scorer, \"mae\": mae_scorer, \"r2\": r2_scorer},\n",
    "        refit=\"rmse\",                # pick best by RMSE\n",
    "        cv=tscv(n_splits),\n",
    "        n_jobs=-1, verbose=0, return_train_score=False,\n",
    "    )\n",
    "    gs.fit(X, y)\n",
    "\n",
    "    # Save best model (refit on full data by GridSearchCV)\n",
    "    outp = MODELS / f\"{symbol}_ridge_reg_tuned.pkl\"\n",
    "    joblib.dump({\"model\": gs.best_estimator_, \"features\": feat_names, \"best_params\": gs.best_params_}, outp)\n",
    "\n",
    "    # Log CV results\n",
    "    res = pd.DataFrame(gs.cv_results_)\n",
    "    res.to_csv(REPORTS / f\"day7_{symbol}_ridge_grid.csv\", index=False)\n",
    "\n",
    "    # Summarize metrics\n",
    "    best = dict(symbol=symbol, algo=\"ridge_reg\", **gs.best_params_)\n",
    "    # Compute CV mean scores from cv_results_\n",
    "    best[\"mean_test_rmse\"] = res.loc[res[\"rank_test_rmse\"].idxmin(), \"mean_test_rmse\"]\n",
    "    best[\"mean_test_mae\"]  = res.loc[res[\"rank_test_rmse\"].idxmin(), \"mean_test_mae\"]\n",
    "    best[\"mean_test_r2\"]   = res.loc[res[\"rank_test_rmse\"].idxmin(), \"mean_test_r2\"]\n",
    "    return pd.DataFrame([best])\n",
    "\n",
    "def tune_hgb(symbol: str, n_splits=5):\n",
    "    df = load_dataset(symbol)\n",
    "    X, y, feat_names = make_X_y(df, \"reg\")\n",
    "\n",
    "    pipe = Pipeline([(\"hgb\", HistGradientBoostingRegressor(random_state=42))])\n",
    "    gs = GridSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_grid=hgb_grid,\n",
    "        scoring={\"rmse\": rmse_scorer, \"mae\": mae_scorer, \"r2\": r2_scorer},\n",
    "        refit=\"rmse\",\n",
    "        cv=tscv(n_splits),\n",
    "        n_jobs=-1, verbose=0, return_train_score=False,\n",
    "    )\n",
    "    gs.fit(X, y)\n",
    "\n",
    "    outp = MODELS / f\"{symbol}_hgb_reg_tuned.pkl\"\n",
    "    joblib.dump({\"model\": gs.best_estimator_, \"features\": feat_names, \"best_params\": gs.best_params_}, outp)\n",
    "\n",
    "    res = pd.DataFrame(gs.cv_results_)\n",
    "    res.to_csv(REPORTS / f\"day7_{symbol}_hgb_grid.csv\", index=False)\n",
    "\n",
    "    best = dict(symbol=symbol, algo=\"hgb_reg\", **gs.best_params_)\n",
    "    best[\"mean_test_rmse\"] = res.loc[res[\"rank_test_rmse\"].idxmin(), \"mean_test_rmse\"]\n",
    "    best[\"mean_test_mae\"]  = res.loc[res[\"rank_test_rmse\"].idxmin(), \"mean_test_mae\"]\n",
    "    best[\"mean_test_r2\"]   = res.loc[res[\"rank_test_rmse\"].idxmin(), \"mean_test_r2\"]\n",
    "    return pd.DataFrame([best])\n",
    "\n",
    "def tune_logit(symbol: str, n_splits=5):\n",
    "    df = load_dataset(symbol)\n",
    "    X, y, feat_names = make_X_y(df, \"cls\")\n",
    "\n",
    "    pipe = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                     (\"logit\", LogisticRegression())])\n",
    "\n",
    "    gs = GridSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_grid=logit_grid,\n",
    "        # Use built-in scorers by name\n",
    "        scoring={\"auc\": \"roc_auc\", \"f1\": \"f1\", \"acc\": \"accuracy\"},\n",
    "        refit=\"auc\",\n",
    "        cv=TimeSeriesSplit(n_splits=n_splits),\n",
    "        n_jobs=-1, verbose=0, return_train_score=False,\n",
    "    )\n",
    "    gs.fit(X, y)\n",
    "\n",
    "    outp = MODELS / f\"{symbol}_logit_cls_tuned.pkl\"\n",
    "    joblib.dump({\"model\": gs.best_estimator_, \"features\": feat_names, \"best_params\": gs.best_params_}, outp)\n",
    "\n",
    "    res = pd.DataFrame(gs.cv_results_)\n",
    "    res.to_csv(REPORTS / f\"day7_{symbol}_logit_grid.csv\", index=False)\n",
    "\n",
    "    best = dict(symbol=symbol, algo=\"logit_cls\", **gs.best_params_)\n",
    "    best[\"mean_test_auc\"] = res.loc[res[\"rank_test_auc\"].idxmin(), \"mean_test_auc\"]\n",
    "    best[\"mean_test_f1\"]  = res.loc[res[\"rank_test_auc\"].idxmin(), \"mean_test_f1\"]\n",
    "    best[\"mean_test_acc\"] = res.loc[res[\"rank_test_auc\"].idxmin(), \"mean_test_acc\"]\n",
    "    return pd.DataFrame([best])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0847b1c-f1c7-4c5c-860e-112d5866de68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>algo</th>\n",
       "      <th>ridge__alpha</th>\n",
       "      <th>mean_test_rmse</th>\n",
       "      <th>mean_test_mae</th>\n",
       "      <th>mean_test_r2</th>\n",
       "      <th>hgb__learning_rate</th>\n",
       "      <th>hgb__max_depth</th>\n",
       "      <th>hgb__max_leaf_nodes</th>\n",
       "      <th>hgb__min_samples_leaf</th>\n",
       "      <th>logit__C</th>\n",
       "      <th>logit__max_iter</th>\n",
       "      <th>logit__penalty</th>\n",
       "      <th>logit__solver</th>\n",
       "      <th>mean_test_auc</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>mean_test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QQQ</td>\n",
       "      <td>ridge_reg</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-0.013350</td>\n",
       "      <td>-0.009422</td>\n",
       "      <td>-0.002039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QQQ</td>\n",
       "      <td>hgb_reg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.013421</td>\n",
       "      <td>-0.009499</td>\n",
       "      <td>-0.015023</td>\n",
       "      <td>0.03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QQQ</td>\n",
       "      <td>logit_cls</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.502383</td>\n",
       "      <td>0.627772</td>\n",
       "      <td>0.534758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VFV.TO</td>\n",
       "      <td>ridge_reg</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-0.010296</td>\n",
       "      <td>-0.007066</td>\n",
       "      <td>-0.024625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VFV.TO</td>\n",
       "      <td>hgb_reg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.010353</td>\n",
       "      <td>-0.007097</td>\n",
       "      <td>-0.034905</td>\n",
       "      <td>0.03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VFV.TO</td>\n",
       "      <td>logit_cls</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.508130</td>\n",
       "      <td>0.626793</td>\n",
       "      <td>0.532325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XEQT.TO</td>\n",
       "      <td>ridge_reg</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-0.008206</td>\n",
       "      <td>-0.006074</td>\n",
       "      <td>-0.037732</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XEQT.TO</td>\n",
       "      <td>hgb_reg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.008368</td>\n",
       "      <td>-0.006151</td>\n",
       "      <td>-0.086785</td>\n",
       "      <td>0.03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XEQT.TO</td>\n",
       "      <td>logit_cls</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.510294</td>\n",
       "      <td>0.527618</td>\n",
       "      <td>0.497561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    symbol       algo  ridge__alpha  mean_test_rmse  mean_test_mae  \\\n",
       "0      QQQ  ridge_reg         100.0       -0.013350      -0.009422   \n",
       "1      QQQ    hgb_reg           NaN       -0.013421      -0.009499   \n",
       "2      QQQ  logit_cls           NaN             NaN            NaN   \n",
       "3   VFV.TO  ridge_reg         100.0       -0.010296      -0.007066   \n",
       "4   VFV.TO    hgb_reg           NaN       -0.010353      -0.007097   \n",
       "5   VFV.TO  logit_cls           NaN             NaN            NaN   \n",
       "6  XEQT.TO  ridge_reg         100.0       -0.008206      -0.006074   \n",
       "7  XEQT.TO    hgb_reg           NaN       -0.008368      -0.006151   \n",
       "8  XEQT.TO  logit_cls           NaN             NaN            NaN   \n",
       "\n",
       "   mean_test_r2  hgb__learning_rate  hgb__max_depth  hgb__max_leaf_nodes  \\\n",
       "0     -0.002039                 NaN             NaN                  NaN   \n",
       "1     -0.015023                0.03             3.0                 15.0   \n",
       "2           NaN                 NaN             NaN                  NaN   \n",
       "3     -0.024625                 NaN             NaN                  NaN   \n",
       "4     -0.034905                0.03             3.0                 15.0   \n",
       "5           NaN                 NaN             NaN                  NaN   \n",
       "6     -0.037732                 NaN             NaN                  NaN   \n",
       "7     -0.086785                0.03             3.0                 15.0   \n",
       "8           NaN                 NaN             NaN                  NaN   \n",
       "\n",
       "   hgb__min_samples_leaf  logit__C  logit__max_iter logit__penalty  \\\n",
       "0                    NaN       NaN              NaN            NaN   \n",
       "1                   10.0       NaN              NaN            NaN   \n",
       "2                    NaN       0.1            200.0             l2   \n",
       "3                    NaN       NaN              NaN            NaN   \n",
       "4                   50.0       NaN              NaN            NaN   \n",
       "5                    NaN       5.0            200.0             l2   \n",
       "6                    NaN       NaN              NaN            NaN   \n",
       "7                   20.0       NaN              NaN            NaN   \n",
       "8                    NaN       0.1            200.0             l2   \n",
       "\n",
       "  logit__solver  mean_test_auc  mean_test_f1  mean_test_acc  \n",
       "0           NaN            NaN           NaN            NaN  \n",
       "1           NaN            NaN           NaN            NaN  \n",
       "2         lbfgs       0.502383      0.627772       0.534758  \n",
       "3           NaN            NaN           NaN            NaN  \n",
       "4           NaN            NaN           NaN            NaN  \n",
       "5         lbfgs       0.508130      0.626793       0.532325  \n",
       "6           NaN            NaN           NaN            NaN  \n",
       "7           NaN            NaN           NaN            NaN  \n",
       "8         lbfgs       0.510294      0.527618       0.497561  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/itzronald/Desktop/trend-predictor/reports/day7_best_models_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Tuning models using search for all the fund symbols\n",
    "all_rows = []\n",
    "for sym in SYMBOLS:\n",
    "    all_rows.append(tune_ridge(sym))\n",
    "    all_rows.append(tune_hgb(sym))\n",
    "    all_rows.append(tune_logit(sym))\n",
    "\n",
    "day7_summary = pd.concat(all_rows, ignore_index=True)\n",
    "display(day7_summary)\n",
    "\n",
    "out_csv = REPORTS / \"day7_best_models_summary.csv\"\n",
    "day7_summary.to_csv(out_csv, index=False)\n",
    "print(\"Saved:\", out_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adab9c99-a0d5-4320-ae78-6ac6178892a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>yhat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013280</td>\n",
       "      <td>-0.002836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.052206</td>\n",
       "      <td>-0.002422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.003359</td>\n",
       "      <td>-0.006269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011709</td>\n",
       "      <td>-0.003769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.005559</td>\n",
       "      <td>-0.003456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          y      yhat\n",
       "0  0.013280 -0.002836\n",
       "1  0.052206 -0.002422\n",
       "2 -0.003359 -0.006269\n",
       "3  0.011709 -0.003769\n",
       "4 -0.005559 -0.003456"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick test of tuned ridge regression model with one symbol\n",
    "\n",
    "sym = SYMBOLS[0]\n",
    "bundle = joblib.load(MODELS / f\"{sym}_ridge_reg_tuned.pkl\")\n",
    "mdl, feats = bundle[\"model\"], bundle[\"features\"]\n",
    "df = load_dataset(sym)\n",
    "X, y, feat_names = make_X_y(df, \"reg\")\n",
    "assert feat_names == feats, \"Feature mismatch\"\n",
    "yhat = mdl.predict(X)\n",
    "pd.DataFrame({\"y\": y, \"yhat\": yhat}).head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
